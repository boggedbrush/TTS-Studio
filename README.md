# TTS Studio

A state-of-the-art text-to-speech web application featuring Voice Design, Voice Clone, and Custom Voice modes. Built with Next.js 14 (React + TypeScript + Tailwind CSS) and Python FastAPI.

![TTS Studio](https://img.shields.io/badge/TTS-Studio-violet?style=for-the-badge)
![Next.js](https://img.shields.io/badge/Next.js-14-black?style=flat-square)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green?style=flat-square)
![License](https://img.shields.io/badge/License-MIT-blue?style=flat-square)

## âœ¨ Features

### Three Powerful TTS Modes

1. **Voice Design** âœ¨  
   Create entirely new voices from natural language descriptions. No reference audio needed.

2. **Voice Clone** ğŸ­  
   Clone any voice from a short audio sample (5-15 seconds). High-fidelity reproduction.

3. **Custom Voice** ğŸ¤  
   Use 9 premium pre-trained speakers across multiple languages with style instructions.

### Premium UI/UX

- ğŸŒ“ Dark/Light theme with smooth transitions
- ğŸ¨ Gradient glassmorphism design
- ğŸµ Advanced audio player with waveform visualization
- âŒ¨ï¸ Keyboard shortcuts (Space, J, K, L, M)
- ğŸ“± Fully responsive mobile-first design
- â™¿ Accessible (WCAG compliant, keyboard navigation, reduced motion)

### Technical Features

- ğŸš€ 97ms end-to-end latency (GPU)
- ğŸŒ 10+ languages supported
- ğŸ’¾ Local history with IndexedDB
- ğŸ”„ Request cancellation
- ğŸ“Š Real-time generation status

## ğŸ–¥ï¸ System Requirements

### Hardware

- **GPU (Recommended)**: NVIDIA GPU with CUDA 11.8+ OR AMD GPU with ROCm 6.0+
- **RAM**: 16GB minimum, 32GB recommended
- **VRAM**: 8GB minimum for 0.6B models, 16GB for 1.7B models
- **CPU Fallback**: Works on CPU but significantly slower

### Software

- **Node.js** 18+ and npm
- **Python** 3.10 or higher (3.9 and below are not supported)
- **PyTorch** 2.0+ with CUDA or ROCm support

## ğŸš€ Quick Start

### Option 1: One-Liner Scripts (Recommended)

These scripts auto-detect your GPU and set everything up for you:

By default, native scripts run the frontend in **production mode** (`next build` + `next start`).
Use `--dev` for hot reload development mode.

**Linux:**
```bash
git clone https://github.com/boggedbrush/TTS-Space.git && cd TTS-Space
./scripts/run-linux.sh
# Dev mode (hot reload):
./scripts/run-linux.sh --dev
```

**macOS:**
```bash
git clone https://github.com/boggedbrush/TTS-Space.git && cd TTS-Space
./scripts/run-macos.sh
# Dev mode (hot reload):
./scripts/run-macos.sh --dev
```

**Windows (PowerShell):**
```powershell
git clone https://github.com/boggedbrush/TTS-Space.git; cd TTS-Space
.\scripts\run-windows.ps1
# Dev mode (hot reload):
.\scripts\run-windows.ps1 -Dev
```

**Windows (CMD):**
```cmd
git clone https://github.com/boggedbrush/TTS-Space.git && cd TTS-Space
scripts\run-windows.bat
REM Dev mode (hot reload):
scripts\run-windows.bat --dev
```

### Update Existing Install

Use the update scripts to pull latest code (when your working tree is clean), refresh dependencies, and rebuild the production frontend.

**macOS/Linux:**
```bash
./scripts/update.sh
# Skip frontend build:
./scripts/update.sh --dev
# Skip git pull:
./scripts/update.sh --skip-git
```

**Windows (PowerShell):**
```powershell
.\scripts\update-windows.ps1
# Skip frontend build:
.\scripts\update-windows.ps1 -Dev
# Skip git pull:
.\scripts\update-windows.ps1 -SkipGit
```

**Windows (CMD):**
```cmd
scripts\update-windows.bat
REM Skip frontend build:
scripts\update-windows.bat --dev
REM Skip git pull:
scripts\update-windows.bat --skip-git
```

### Option 2: Manual Setup

#### 1. Clone the Repository

```bash
git clone https://github.com/boggedbrush/TTS-Space.git
cd TTS-Space
```

### 2. Frontend Setup

```bash
cd frontend
npm install
npm run dev
```

Frontend will be available at `http://localhost:3000`

### 3. Backend Setup

#### For NVIDIA GPUs (CUDA)

```bash
cd backend
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
pip install -r requirements.txt
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

#### For AMD GPUs (ROCm)

```bash
cd backend
python -m venv venv
source venv/bin/activate

# Install PyTorch with ROCm support
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/rocm6.0

pip install -r requirements.txt
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

#### For CPU (Slow, for testing only)

```bash
cd backend
python -m venv venv
source venv/bin/activate
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install -r requirements.txt
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

Backend will be available at `http://localhost:8000`

## ğŸ³ Docker Deployment

### Auto-Detect Script (Recommended)

Automatically selects CPU/NVIDIA/AMD compose files:

```bash
./scripts/run-docker.sh
```

Force GPU type:

```bash
./scripts/run-docker.sh --cpu
./scripts/run-docker.sh --nvidia
./scripts/run-docker.sh --amd
```

### NVIDIA GPU

```bash
docker compose up --build
```

### AMD GPU (ROCm)

```bash
docker compose -f docker-compose.yml -f docker-compose.amd.yml up --build
```

## ğŸ§ª Docker Dev Mode (Hot Reload)

Use the dev override to enable live reload for both frontend and backend.

### Auto-Detect (Recommended)

```bash
./scripts/run-docker.sh --dev
```

### CPU (Docker, no GPU)

```bash
docker compose -f docker-compose.yml -f docker-compose.dev.yml up --build
```

### NVIDIA GPU

```bash
docker compose -f docker-compose.yml -f docker-compose.nvidia.yml -f docker-compose.dev.yml up --build
```

### AMD GPU (ROCm)

```bash
docker compose -f docker-compose.yml -f docker-compose.amd.yml -f docker-compose.dev.yml up --build
```

## ğŸ“ Project Structure

```
TTS-Space/
â”œâ”€â”€ frontend/                 # Next.js frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/             # App Router pages
â”‚   â”‚   â”‚   â”œâ”€â”€ voice-design/
â”‚   â”‚   â”‚   â”œâ”€â”€ voice-clone/
â”‚   â”‚   â”‚   â””â”€â”€ custom-voice/
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”‚   â””â”€â”€ ui/          # shadcn/ui components
â”‚   â”‚   â”œâ”€â”€ hooks/           # Custom React hooks
â”‚   â”‚   â””â”€â”€ lib/             # Utilities and API client
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tailwind.config.ts
â”œâ”€â”€ backend/                  # FastAPI backend
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ routers/         # API endpoints
â”‚   â”‚   â”œâ”€â”€ services/        # TTS model manager
â”‚   â”‚   â””â”€â”€ main.py          # FastAPI app
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ scripts/                  # Native run and update scripts
â”‚   â”œâ”€â”€ run-linux.sh         # Linux (CUDA/ROCm/CPU)
â”‚   â”œâ”€â”€ run-macos.sh         # macOS (MPS/CPU)
â”‚   â”œâ”€â”€ run-windows.bat      # Windows CMD
â”‚   â”œâ”€â”€ run-windows.ps1      # Windows PowerShell
â”‚   â”œâ”€â”€ update.sh            # macOS/Linux updater
â”‚   â”œâ”€â”€ update-windows.bat   # Windows CMD updater
â”‚   â””â”€â”€ update-windows.ps1   # Windows PowerShell updater
â”œâ”€â”€ docker-compose.yml        # Docker (base config)
â”œâ”€â”€ docker-compose.amd.yml    # Docker AMD GPU override
â”œâ”€â”€ docker-compose.nvidia.yml # Docker NVIDIA GPU override
â””â”€â”€ README.md
```

## ğŸ”Œ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/health` | GET | Health check |
| `/api/info` | GET | API capabilities |
| `/api/voice-design` | POST | Generate from description |
| `/api/voice-clone` | POST | Clone from audio |
| `/api/custom-voice` | POST | Use pre-trained speaker |

| `/api/custom-voice` | POST | Use pre-trained speaker |

## ğŸŒ Remote Access / Tunnels

To access the application remotely using Cloudflare Tunnels, ngrok, or other tunneling services where the frontend and backend may be on different URLs:

1. Expose your backend (port 8000) via a tunnel
2. Set the `NEXT_PUBLIC_API_URL` environment variable when building/running the frontend

```bash
# Example with Cloudflare Tunnel
export NEXT_PUBLIC_API_URL="https://your-backend-tunnel.trycloudflare.com/api"
npm run dev
```

This ensures the frontend can communicate with the backend regardless of the domain or port configuration.

### Example: Voice Design

```bash
curl -X POST http://localhost:8000/api/voice-design \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Hello, this is a test.",
    "language": "English",
    "voice_description": "A warm, friendly female voice with American accent"
  }' \
  --output audio.wav
```

## âŒ¨ï¸ Keyboard Shortcuts

| Key | Action |
|-----|--------|
| `Space` | Play/Pause |
| `J` | Rewind 10 seconds |
| `L` | Forward 10 seconds |
| `K` | Play/Pause (alternate) |
| `M` | Toggle mute |

## ğŸŒ Supported Languages

- Auto (automatic detection)
- Chinese (ä¸­æ–‡)
- English
- Japanese (æ—¥æœ¬èª)
- Korean (í•œêµ­ì–´)
- French (FranÃ§ais)
- German (Deutsch)
- Spanish (EspaÃ±ol)
- Portuguese (PortuguÃªs)
- Russian (Ğ ÑƒÑÑĞºĞ¸Ğ¹)

## ğŸ™ï¸ Available Speakers (Custom Voice)

| Speaker | Gender | Native Language | Notes |
|---------|--------|-----------------|-------|
| Aiden | Male | English | Native fluency |
| Ryan | Male | English | Native fluency |
| Dylan | Male | English | Chinese accent |
| Eric | Male | English | Chinese accent |
| Serena | Female | English | Chinese accent |
| Ono Anna | Female | Japanese | |
| Sohee | Female | Korean | |
| Uncle Fu | Male | Chinese | Old man voice |
| Vivian | Female | Chinese | |

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Default |
|----------|-------------|---------|
| `CUDA_VISIBLE_DEVICES` | GPU device(s) to use | `0` |
| `HF_HOME` | Hugging Face cache directory | `~/.cache/huggingface` |

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

## ğŸ™ Acknowledgments

- [Qwen3-TTS](https://github.com/QwenLM/Qwen3-TTS) by Alibaba Cloud
- [Next.js](https://nextjs.org/) by Vercel
- [FastAPI](https://fastapi.tiangolo.com/)
- [shadcn/ui](https://ui.shadcn.com/)
